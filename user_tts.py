import sys
sys.path.append('third_party/Matcha-TTS')
sys.path.append('third_party/WeTextProcessing')
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio
from tqdm import tqdm
import os
import json
import torch
import time
import argparse
import gc
from functools import partial

# ì‹¤ì‹œê°„ ì¶œë ¥ ë³´ì¥
print = partial(print, flush=True)

# PyTorch ê³ ì • ì„±ëŠ¥ ì„¤ì •
torch.set_float32_matmul_precision('high')
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# Configuration
MODEL_PATH = 'pretrained_models/CosyVoice2-0.5B'
FILE_PATH = 'ko_dataset.jsonl'
OUTPUT_DIR = 'wavs'
PROMPT_PATH = './asset/zero_shot_prompt.wav'
SPEAKER_DESC = 'ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ í•œêµ­ì–´ ì—¬ì„± ëª©ì†Œë¦¬ë¡œ ë§í•´ì¤˜.'
MAX_SAMPLES = 8000
START_INDEX = 1
NUM_MESSAGES = 5000

# Argument parser
parser = argparse.ArgumentParser(description='Process CosyVoice2 messages with custom start index and count.')
parser.add_argument('--start-index', type=int, default=START_INDEX)
parser.add_argument('--num-messages', type=int, default=NUM_MESSAGES)
parser.add_argument('--memory-limit', type=float, default=0.7)
args = parser.parse_args()
START_INDEX = args.start_index
NUM_MESSAGES = args.num_messages
MEMORY_LIMIT = args.memory_limit

# Output ë””ë ‰í„°ë¦¬ ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)

# GPU ë©”ëª¨ë¦¬ ë¹„ìš°ê¸° í•¨ìˆ˜
def clear_memory():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()

# ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ í•¨ìˆ˜
def extract_user_messages(file_path, max_messages=8000):
    messages = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip():
                    continue
                json_obj = json.loads(line)
                if 'conversations' in json_obj:
                    for msg in json_obj['conversations']:
                        if msg['from'] == 'user':
                            messages.append(msg['value'])
                            if len(messages) >= max_messages:
                                return messages
        return messages
    except Exception as e:
        print(f"âŒ Error reading file {file_path}: {e}")
        return []

# ë‹¨ì¼ ë¬¸ì¥ ì²˜ë¦¬ í•¨ìˆ˜
@torch.inference_mode()
def process_single_text(cosyvoice, text, output_path, prompt_speech_16k, retries=1):
    from torch.cuda.amp import autocast
    try:
        clear_memory()
        torch.cuda.empty_cache()

        with autocast(dtype=torch.float16):
            result = next(cosyvoice.inference_zero_shot(
                tts_text=text,
                prompt_text=SPEAKER_DESC,  # ìŠ¤íƒ€ì¼ ì ìš©ì— í•„ìš”
                prompt_speech_16k=prompt_speech_16k,
                stream=False,
                text_frontend=False
            ))

        torchaudio.save(output_path, result['tts_speech'], cosyvoice.sample_rate)
        return True

    except RuntimeError as e:
        if "CUDA out of memory" in str(e) and retries > 0:
            print("âš ï¸ CUDA OOM - retrying after 5s...")
            clear_memory()
            torch.cuda.empty_cache()
            time.sleep(5)
            return process_single_text(cosyvoice, text, output_path, prompt_speech_16k, retries - 1)
        else:
            print(f"âŒ RuntimeError: {e}")
    except Exception as e:
        print(f"âŒ Other error: {e}")
    return False

# ì‹¤í–‰
try:
    print(f"ğŸ“¥ Loading dataset from {FILE_PATH}")
    user_messages = extract_user_messages(FILE_PATH, MAX_SAMPLES)

    if not user_messages:
        print("ğŸš« No messages found.")
        sys.exit(1)

    start_idx = START_INDEX - 1
    if start_idx >= len(user_messages):
        print(f"ğŸš« Start index {START_INDEX} exceeds message count.")
        sys.exit(1)

    if NUM_MESSAGES < 1:
        print("ğŸš« NUM_MESSAGES must be at least 1.")
        sys.exit(1)

    max_available = len(user_messages) - start_idx
    if NUM_MESSAGES > max_available:
        print(f"âš ï¸ Adjusting NUM_MESSAGES to available: {max_available}")
        NUM_MESSAGES = max_available

    user_messages = user_messages[start_idx:start_idx + NUM_MESSAGES]
    print(f"ğŸ”„ Processing {len(user_messages)} messages from index {START_INDEX}...")

    # Prompt ìŒì„± ë¡œë”© ë° ì•ë¶€ë¶„ ë…¸ì´ì¦ˆ ì œê±° (0.5ì´ˆ ì´í›„ë¶€í„° ì‚¬ìš©)
    raw_prompt = load_wav(PROMPT_PATH, 16000)
    prompt_speech_16k = raw_prompt[:, int(0.5 * 16000):]  # 0.5ì´ˆ ì œê±°

    # ë©”ëª¨ë¦¬ í™•ë³´ ë° ëª¨ë¸ ë¡œë”©
    clear_memory()
    if torch.cuda.is_available():
        print("ğŸš€ CUDA available - reserving memory buffer")
        reserve_memory_mb = 2048
        try:
            buffer_tensor = torch.empty(reserve_memory_mb * 1024 * 1024, dtype=torch.uint8, device='cuda')
            print(f"ğŸ§  Reserved {reserve_memory_mb}MB buffer on GPU")
        except Exception as e:
            print(f"âš ï¸ Warning: Memory reserve failed: {e}")

    print(f"ğŸ”§ Loading CosyVoice2 model from {MODEL_PATH}")
    load_start = time.time()
    cosyvoice = CosyVoice2(
        MODEL_PATH,
        load_jit=False,
        load_trt=False,
        fp16=True,
        use_flow_cache=False
    )
    cosyvoice = cosyvoice.half()  # ì „ì²´ ëª¨ë¸ FP16 ì ìš©
    print(f"âœ… Model loaded in {time.time() - load_start:.2f}s")

    # ë©”ì‹œì§€ ë°˜ë³µ ì²˜ë¦¬
    total_start = time.time()
    processed_count = 0
    success_count = 0

    for i, text in enumerate(tqdm(user_messages, desc="ğŸ”Š Synthesizing", ncols=80)):
        output_path = os.path.join(OUTPUT_DIR, f'sample_{start_idx + i}.wav')
        success = process_single_text(cosyvoice, text, output_path, prompt_speech_16k, retries=2)
        if success:
            print(f"âœ… sample_{start_idx + i} saved")
            success_count += 1
        processed_count += 1

    # ì²˜ë¦¬ ê²°ê³¼ ì¶œë ¥
    total_time = time.time() - total_start
    print(f"\nğŸ‰ Finished: {processed_count} processed / {success_count} succeeded")
    print(f"â±ï¸ Total time: {total_time:.2f}s, Avg per message: {total_time / (processed_count or 1):.2f}s")
    print(f"ğŸ“ Output saved in: {OUTPUT_DIR}")

except Exception as e:
    print(f"â— Unhandled error: {e}")
finally:
    if 'buffer_tensor' in locals():
        del buffer_tensor
    if 'cosyvoice' in locals():
        del cosyvoice
    clear_memory()
